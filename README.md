# Privacy-Program - PET
# Privacy Attacks
  - linking attack
  - membership inference attack
  - local privacy poison attack 
  - model inversion attack 
  - white box access attack (secret sharer)
  - 
# Traditional PET 
# Anonymization or pseudoanonymization 
  - Redaction
  - Tokenization
  - Hashing
  - Generalization
  - k-anonymity (Homogeneity Attack, Background Knowledge Attack, NP-hard, naive algorithm is ğ‘‚(ğ‘›2))
  - â„“-diversity, t-closeness, (Î±,k)-anonymity, and Î´-presence
  - de-identification 
   
# Encryption 
  - Homomorphic encryption (PHE, SHE, FHE)
  - In-transit encryption
  - At rest encryption
  
# Zero Knowledge Proofs
  - prover, verifier, no information leakage
  - completeness, soundness, zero knowledgeness
  
# Trusted Execution  Environment (TEE) 
  - assured workloads, confidential computing, shielded VMs 
  
# Secure Multiparty Computing (MPC)

# Differential Privacy 
  - Æ-DP:  Random Response mechanism 
  - Æ-DP:  Laplace mechanism ğ¹(ğ‘¥) = ğ‘“(ğ‘¥) + Lap (ğ‘ /ğœ–)
  - (Æ, ğ›¿)-DP: Gausian mechanism  
    - ğ–¯ğ—‹[ğ¹(ğ‘¥)=ğ‘†]â‰¤ğ‘’xp(ğœ–)ğ–¯ğ—‹[ğ¹(ğ‘¥â€²)=ğ‘ ]+ğ›¿, 
      - With probability 1âˆ’ğ›¿, ğ–¯ğ—‹[ğ¹(ğ‘¥)=ğ‘†]/ğ–¯ğ—‹[ğ¹(ğ‘¥â€²)=ğ‘ ]â‰¤ğ‘’ğœ– 
      - With probability ğ›¿, we get no guarantee at all
      - ğ›¿  to be very small - usually  1/ğ‘›(2)  or less
  - Renyi Mechanism
# Type of Queries
  - sequential (kÆ), parallel(Æ), post-processing (Æ1+Æ2)
  - count, histogram
# Federated Analytics
  - TensorFlow Privacy 

# Tools 
  - NIST Tool List https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id/tools
  - FAIR  Factors Analysis in Information Risk, inviduals 
  - NIST Privacy Risk Assessment Methodology (PRAM) : NISTIR 8062,  org privacy, cybersecurity, business, and IT personnel
  - 
# Readings
  - Differential Privacy: A Primer for a Non-Technical Audience
  - 
